{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a docker container for training/deploying our classifier\n",
    "In this exercise we'll create a Docker image that will have the required code for training and deploying a ML model. In this particular example, we'll use scikit-learn (https://scikit-learn.org/) and the **Random Forest Tree** implementation of that library to train a flower classifier. The dataset used in this experiment is a toy dataset called Iris (http://archive.ics.uci.edu/ml/datasets/iris). The clallenge itself is very basic, so you can focus on the mechanics and the features of this automated environment.\n",
    "\n",
    "A first pipeline will be executed at the end of this exercise, automatically. It will get the assets you'll push to a Git repo, build this image and push it to ECR, a docker image repository, used by SageMaker.\n",
    "\n",
    "> **Question**: Why would I create a Scikit-learn container from scratch if SageMaker already offerst one (https://docs.aws.amazon.com/sagemaker/latest/dg/sklearn.html).  \n",
    "> **Answer**: This is an exercise and the idea here is also to show you how you can create your own container. In a real-life scenario, the best approach is to use the native container offered by SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1 - Creating the assets required to build/test a docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Let's start by creating the training script!\n",
    "\n",
    "As you can see, this is a very basic example of Scikit-Learn. Nothing fancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def load_dataset(path):\n",
    "    # Take the set of files and read them all into a single pandas dataframe\n",
    "    files = [ os.path.join(path, file) for file in os.listdir(path) ]\n",
    "    \n",
    "    if len(files) == 0:\n",
    "        raise ValueError(\"Invalid # of files in dir: {}\".format(path))\n",
    "\n",
    "    raw_data = [ pd.read_csv(file, sep=\",\", header=None ) for file in files ]\n",
    "    data = pd.concat(raw_data)\n",
    "\n",
    "    # labels are in the first column\n",
    "    y = data.iloc[:,0]\n",
    "    X = data.iloc[:,1:]\n",
    "    return X,y\n",
    "    \n",
    "def start(args):\n",
    "    print(\"Training mode\")\n",
    "\n",
    "    try:\n",
    "        X_train, y_train = load_dataset(args.training)\n",
    "        X_test, y_test = load_dataset(args.testing)\n",
    "        \n",
    "        hyperparameters = {\n",
    "            \"max_depth\": args.max_depth,\n",
    "            \"verbose\": 1, # show all logs\n",
    "            \"n_jobs\": args.n_jobs,\n",
    "            \"n_estimators\": args.n_estimators\n",
    "        }\n",
    "        print(\"Training the classifier\")\n",
    "        model = RandomForestClassifier()\n",
    "        model.set_params(**hyperparameters)\n",
    "        model.fit(X_train, y_train)\n",
    "        print(\"Score: {}\".format( model.score(X_test, y_test)) )\n",
    "        joblib.dump(model, open(os.path.join(args.model_dir, \"iris_model.pkl\"), \"wb\"))\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Write out an error file. This will be returned as the failureReason in the\n",
    "        # DescribeTrainingJob result.\n",
    "        trc = traceback.format_exc()\n",
    "        with open(os.path.join(output_path, \"failure\"), \"w\") as s:\n",
    "            s.write(\"Exception during training: \" + str(e) + \"\\\\n\" + trc)\n",
    "            \n",
    "        # Printing this causes the exception to be in the training job logs, as well.\n",
    "        print(\"Exception during training: \" + str(e) + \"\\\\n\" + trc, file=sys.stderr)\n",
    "        \n",
    "        # A non-zero exit code causes the training job to be marked as Failed.\n",
    "        sys.exit(255)\n",
    "        \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Ok. Lets then create the handler. The **Inference Handler** is how we use the SageMaker Inference Toolkit to encapsulate our code and expose it as a SageMaker container.\n",
    "SageMaker Inference Toolkit: https://github.com/aws/sagemaker-inference-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile handler.py\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "from sagemaker_inference.default_inference_handler import DefaultInferenceHandler\n",
    "from sagemaker_inference.default_handler_service import DefaultHandlerService\n",
    "from sagemaker_inference import content_types, errors, transformer, encoder, decoder\n",
    "\n",
    "class HandlerService(DefaultHandlerService, DefaultInferenceHandler):\n",
    "    def __init__(self):\n",
    "        op = transformer.Transformer(default_inference_handler=self)\n",
    "        super(HandlerService, self).__init__(transformer=op)\n",
    "    \n",
    "    ## Loads the model from the disk\n",
    "    def default_model_fn(self, model_dir):\n",
    "        model_filename = os.path.join(model_dir, \"iris_model.pkl\")\n",
    "        return joblib.load(open(model_filename, \"rb\"))\n",
    "    \n",
    "    ## Parse and check the format of the input data\n",
    "    def default_input_fn(self, input_data, content_type):\n",
    "        if content_type != \"text/csv\":\n",
    "            raise Exception(\"Invalid content-type: %s\" % content_type)\n",
    "        return decoder.decode(input_data, content_type).reshape(1,-1)\n",
    "    \n",
    "    ## Run our model and do the prediction\n",
    "    def default_predict_fn(self, payload, model):\n",
    "        return model.predict( payload ).tolist()\n",
    "    \n",
    "    ## Gets the prediction output and format it to be returned to the user\n",
    "    def default_output_fn(self, prediction, accept):\n",
    "        if accept != \"text/csv\":\n",
    "            raise Exception(\"Invalid accept: %s\" % accept)\n",
    "        return encoder.encode(prediction, accept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Now we need to create the entrypoint of our container. The main function\n",
    "\n",
    "We'll use **SageMaker Training Toolkit** (https://github.com/aws/sagemaker-training-toolkit) to work with the arguments and environment variables defined by SageMaker. This library will make our code simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "import train\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "from sagemaker_inference import model_server\n",
    "from sagemaker_training import environment\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) < 2 or ( not sys.argv[1] in [ \"serve\", \"train\" ] ):\n",
    "        raise Exception(\"Invalid argument: you must inform 'train' for training mode or 'serve' predicting mode\") \n",
    "        \n",
    "    if sys.argv[1] == \"train\":\n",
    "        \n",
    "        env = environment.Environment()\n",
    "        \n",
    "        parser = argparse.ArgumentParser()\n",
    "        # https://github.com/aws/sagemaker-training-toolkit/blob/master/ENVIRONMENT_VARIABLES.md\n",
    "        parser.add_argument(\"--max-depth\", type=int, default=10)\n",
    "        parser.add_argument(\"--n-jobs\", type=int, default=env.num_cpus)\n",
    "        parser.add_argument(\"--n-estimators\", type=int, default=120)\n",
    "        \n",
    "        # reads input channels training and testing from the environment variables\n",
    "        parser.add_argument(\"--training\", type=str, default=env.channel_input_dirs[\"training\"])\n",
    "        parser.add_argument(\"--testing\", type=str, default=env.channel_input_dirs[\"testing\"])\n",
    "\n",
    "        parser.add_argument(\"--model-dir\", type=str, default=env.model_dir)\n",
    "        \n",
    "        args,unknown = parser.parse_known_args()\n",
    "        train.start(args)\n",
    "    else:\n",
    "        model_server.start_model_server(handler_service=\"serving.handler\")\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Then, we can create the Dockerfile\n",
    "Just pay attention to the packages we'll install in our container. Here, we'll use **SageMaker Inference Toolkit** (https://github.com/aws/sagemaker-inference-toolkit) and **SageMaker Training Toolkit** (https://github.com/aws/sagemaker-training-toolkit) to prepare the container for training/serving our model. **By serving** you can understand: exposing our model as a webservice that can be called through an api call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM python:3.7-buster\n",
    "\n",
    "# Set a docker label to advertise multi-model support on the container\n",
    "LABEL com.amazonaws.sagemaker.capabilities.multi-models=false\n",
    "# Set a docker label to enable container to use SAGEMAKER_BIND_TO_PORT environment variable if present\n",
    "LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
    "\n",
    "RUN apt-get update -y && apt-get -y install --no-install-recommends default-jdk\n",
    "RUN rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "RUN pip --no-cache-dir install multi-model-server sagemaker-inference sagemaker-training\n",
    "RUN pip --no-cache-dir install pandas numpy scipy scikit-learn\n",
    "\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
    "ENV PYTHONPATH=\"/opt/ml/code:${PATH}\"\n",
    "\n",
    "COPY main.py /opt/ml/code/main.py\n",
    "COPY train.py /opt/ml/code/train.py\n",
    "COPY handler.py /opt/ml/code/serving/handler.py\n",
    "\n",
    "ENTRYPOINT [\"python\", \"/opt/ml/code/main.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.5 Finally, let's create the buildspec\n",
    "This file will be used by CodeBuild for creating our Container image.  \n",
    "With this file, CodeBuild will run the \"docker build\" command, using the assets we created above, and deploy the image to the Registry.  \n",
    "As you can see, each command is a bash command that will be executed from inside a Linux Container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing buildspec.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile buildspec.yml\n",
    "version: 0.2\n",
    "\n",
    "phases:\n",
    "  install:\n",
    "    runtime-versions:\n",
    "      docker: 18\n",
    "\n",
    "  pre_build:\n",
    "    commands:\n",
    "      - echo Logging in to Amazon ECR...\n",
    "      - $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION)\n",
    "  build:\n",
    "    commands:\n",
    "      - echo Build started on `date`\n",
    "      - echo Building the Docker image...\n",
    "      - docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .\n",
    "      - docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "\n",
    "  post_build:\n",
    "    commands:\n",
    "      - echo Build completed on `date`\n",
    "      - echo Pushing the Docker image...\n",
    "      - echo docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "      - docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "      - echo $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG > image.url\n",
    "      - echo Done\n",
    "artifacts:\n",
    "  files:\n",
    "    - image.url\n",
    "  name: image_url\n",
    "  discard-paths: yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2 - Local Test: Let's build the image locally and do some tests\n",
    "### 2.1 Building the image locally, first\n",
    "Each SageMaker Jupyter Notebook already has a **docker** envorinment pre-installed. So we can play with Docker containers just using the same environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  66.05kB\n",
      "Step 1/14 : FROM python:3.7-buster\n",
      "3.7-buster: Pulling from library/python\n",
      "\n",
      "\u001b[1Bc4f90ab0: Pulling fs layer \n",
      "\u001b[1B6b19a265: Pulling fs layer \n",
      "\u001b[1Bb6c2f878: Pulling fs layer \n",
      "\u001b[1Bc4b30949: Pulling fs layer \n",
      "\u001b[1B8e764313: Pulling fs layer \n",
      "\u001b[1B6f0e36af: Pulling fs layer \n",
      "\u001b[1Be1fb5d17: Pulling fs layer \n",
      "\u001b[1Bdb2cc9d4: Pulling fs layer \n",
      "\u001b[1B532dd46c: Pull complete 932MB/1.932MBB\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[9A\u001b[2KDownloading   23.2MB/192.2MB\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[9A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2KExtracting  10.03MB/192.2MB\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2KExtracting  62.39MB/192.2MB\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:940a1ddcfbb4411fade27ff9d1bf3985d6c4276da4ee4111deba5ab0788921c5\n",
      "Status: Downloaded newer image for python:3.7-buster\n",
      " ---> e4e55e98f1e0\n",
      "Step 2/14 : LABEL com.amazonaws.sagemaker.capabilities.multi-models=false\n",
      " ---> Running in da1486f25458\n",
      "Removing intermediate container da1486f25458\n",
      " ---> 1f59f308aa78\n",
      "Step 3/14 : LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
      " ---> Running in e1963dfbc580\n",
      "Removing intermediate container e1963dfbc580\n",
      " ---> ef9ee93023d5\n",
      "Step 4/14 : RUN apt-get update -y && apt-get -y install --no-install-recommends default-jdk\n",
      " ---> Running in 834a3072bcc4\n",
      "Get:1 http://security.debian.org/debian-security buster/updates InRelease [65.4 kB]\n",
      "Get:2 http://deb.debian.org/debian buster InRelease [121 kB]\n",
      "Get:3 http://deb.debian.org/debian buster-updates InRelease [51.9 kB]\n",
      "Get:4 http://security.debian.org/debian-security buster/updates/main amd64 Packages [204 kB]\n",
      "Get:5 http://deb.debian.org/debian buster/main amd64 Packages [7905 kB]\n",
      "Get:6 http://deb.debian.org/debian buster-updates/main amd64 Packages [7868 B]\n",
      "Fetched 8355 kB in 2s (5461 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  ca-certificates-java default-jdk-headless default-jre default-jre-headless\n",
      "  java-common libasound2 libasound2-data libavahi-client3 libavahi-common-data\n",
      "  libavahi-common3 libcups2 libdbus-1-3 libdrm-amdgpu1 libdrm-common\n",
      "  libdrm-intel1 libdrm-nouveau2 libdrm-radeon1 libdrm2 libgif7 libgl1\n",
      "  libgl1-mesa-dri libglapi-mesa libglvnd0 libglx-mesa0 libglx0 libllvm7\n",
      "  libnspr4 libnss3 libpciaccess0 libpcsclite1 libsensors-config libsensors5\n",
      "  libx11-xcb1 libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0\n",
      "  libxcb-sync1 libxdamage1 libxfixes3 libxi6 libxshmfence1 libxtst6\n",
      "  libxxf86vm1 openjdk-11-jdk openjdk-11-jdk-headless openjdk-11-jre\n",
      "  openjdk-11-jre-headless\n",
      "Suggested packages:\n",
      "  libasound2-plugins alsa-utils cups-common pciutils pcscd lm-sensors\n",
      "  openjdk-11-demo openjdk-11-source visualvm libnss-mdns fonts-dejavu-extra\n",
      "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
      "  | fonts-wqy-zenhei fonts-indic\n",
      "Recommended packages:\n",
      "  dbus libatk-wrapper-java-jni fonts-dejavu-extra\n",
      "The following NEW packages will be installed:\n",
      "  ca-certificates-java default-jdk default-jdk-headless default-jre\n",
      "  default-jre-headless java-common libasound2 libasound2-data libavahi-client3\n",
      "  libavahi-common-data libavahi-common3 libcups2 libdbus-1-3 libdrm-amdgpu1\n",
      "  libdrm-common libdrm-intel1 libdrm-nouveau2 libdrm-radeon1 libdrm2 libgif7\n",
      "  libgl1 libgl1-mesa-dri libglapi-mesa libglvnd0 libglx-mesa0 libglx0 libllvm7\n",
      "  libnspr4 libnss3 libpciaccess0 libpcsclite1 libsensors-config libsensors5\n",
      "  libx11-xcb1 libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0\n",
      "  libxcb-sync1 libxdamage1 libxfixes3 libxi6 libxshmfence1 libxtst6\n",
      "  libxxf86vm1 openjdk-11-jdk openjdk-11-jdk-headless openjdk-11-jre\n",
      "  openjdk-11-jre-headless\n",
      "0 upgraded, 49 newly installed, 0 to remove and 1 not upgraded.\n",
      "Need to get 279 MB of archives.\n",
      "After this operation, 621 MB of additional disk space will be used.\n",
      "Get:1 http://deb.debian.org/debian buster/main amd64 java-common all 0.71 [14.4 kB]\n",
      "Get:2 http://security.debian.org/debian-security buster/updates/main amd64 openjdk-11-jre-headless amd64 11.0.7+10-3~deb10u1 [37.3 MB]\n",
      "Get:3 http://deb.debian.org/debian buster/main amd64 libavahi-common-data amd64 0.7-4+b1 [122 kB]\n",
      "Get:4 http://deb.debian.org/debian buster/main amd64 libavahi-common3 amd64 0.7-4+b1 [54.6 kB]\n",
      "Get:5 http://deb.debian.org/debian buster/main amd64 libdbus-1-3 amd64 1.12.16-1 [214 kB]\n",
      "Get:6 http://deb.debian.org/debian buster/main amd64 libavahi-client3 amd64 0.7-4+b1 [58.1 kB]\n",
      "Get:7 http://deb.debian.org/debian buster/main amd64 libcups2 amd64 2.2.10-6+deb10u3 [324 kB]\n",
      "Get:8 http://deb.debian.org/debian buster/main amd64 libnspr4 amd64 2:4.20-1 [112 kB]\n",
      "Get:9 http://deb.debian.org/debian buster/main amd64 libnss3 amd64 2:3.42.1-1+deb10u2 [1160 kB]\n",
      "Get:10 http://deb.debian.org/debian buster/main amd64 libasound2-data all 1.1.8-1 [59.6 kB]\n",
      "Get:11 http://deb.debian.org/debian buster/main amd64 libasound2 amd64 1.1.8-1 [361 kB]\n",
      "Get:12 http://deb.debian.org/debian buster/main amd64 libpcsclite1 amd64 1.8.24-1 [58.5 kB]\n",
      "Get:13 http://deb.debian.org/debian buster/main amd64 libxi6 amd64 2:1.7.9-1 [82.6 kB]\n",
      "Get:14 http://deb.debian.org/debian buster/main amd64 libxtst6 amd64 2:1.2.3-1 [27.8 kB]\n",
      "Get:15 http://deb.debian.org/debian buster/main amd64 default-jre-headless amd64 2:1.11-71 [10.9 kB]\n",
      "Get:16 http://deb.debian.org/debian buster/main amd64 ca-certificates-java all 20190405 [15.7 kB]\n",
      "Get:17 http://deb.debian.org/debian buster/main amd64 libglvnd0 amd64 1.1.0-1 [48.6 kB]\n",
      "Get:18 http://deb.debian.org/debian buster/main amd64 libdrm-common all 2.4.97-1 [13.8 kB]\n",
      "Get:19 http://deb.debian.org/debian buster/main amd64 libdrm2 amd64 2.4.97-1 [39.7 kB]\n",
      "Get:20 http://deb.debian.org/debian buster/main amd64 libglapi-mesa amd64 18.3.6-2+deb10u1 [66.3 kB]\n",
      "Get:21 http://deb.debian.org/debian buster/main amd64 libx11-xcb1 amd64 2:1.6.7-1 [190 kB]\n",
      "Get:22 http://deb.debian.org/debian buster/main amd64 libxcb-dri2-0 amd64 1.13.1-2 [101 kB]\n",
      "Get:23 http://deb.debian.org/debian buster/main amd64 libxcb-dri3-0 amd64 1.13.1-2 [100 kB]\n",
      "Get:24 http://deb.debian.org/debian buster/main amd64 libxcb-glx0 amd64 1.13.1-2 [116 kB]\n",
      "Get:25 http://deb.debian.org/debian buster/main amd64 libxcb-present0 amd64 1.13.1-2 [99.1 kB]\n",
      "Get:26 http://deb.debian.org/debian buster/main amd64 libxcb-sync1 amd64 1.13.1-2 [103 kB]\n",
      "Get:27 http://deb.debian.org/debian buster/main amd64 libxfixes3 amd64 1:5.0.3-1 [21.9 kB]\n",
      "Get:28 http://deb.debian.org/debian buster/main amd64 libxdamage1 amd64 1:1.1.4-3+b3 [14.9 kB]\n",
      "Get:29 http://deb.debian.org/debian buster/main amd64 libxshmfence1 amd64 1.3-1 [8820 B]\n",
      "Get:30 http://deb.debian.org/debian buster/main amd64 libxxf86vm1 amd64 1:1.1.4-1+b2 [20.8 kB]\n",
      "Get:31 http://deb.debian.org/debian buster/main amd64 libdrm-amdgpu1 amd64 2.4.97-1 [27.3 kB]\n",
      "Get:32 http://deb.debian.org/debian buster/main amd64 libpciaccess0 amd64 0.14-1 [53.5 kB]\n",
      "Get:33 http://deb.debian.org/debian buster/main amd64 libdrm-intel1 amd64 2.4.97-1 [69.8 kB]\n",
      "Get:34 http://deb.debian.org/debian buster/main amd64 libdrm-nouveau2 amd64 2.4.97-1 [26.3 kB]\n",
      "Get:35 http://deb.debian.org/debian buster/main amd64 libdrm-radeon1 amd64 2.4.97-1 [31.1 kB]\n",
      "Get:36 http://deb.debian.org/debian buster/main amd64 libllvm7 amd64 1:7.0.1-8 [13.0 MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:37 http://deb.debian.org/debian buster/main amd64 libsensors-config all 1:3.5.0-3 [31.6 kB]\n",
      "Get:38 http://deb.debian.org/debian buster/main amd64 libsensors5 amd64 1:3.5.0-3 [52.6 kB]\n",
      "Get:39 http://deb.debian.org/debian buster/main amd64 libgl1-mesa-dri amd64 18.3.6-2+deb10u1 [6685 kB]\n",
      "Get:40 http://deb.debian.org/debian buster/main amd64 libglx-mesa0 amd64 18.3.6-2+deb10u1 [180 kB]\n",
      "Get:41 http://deb.debian.org/debian buster/main amd64 libglx0 amd64 1.1.0-1 [30.0 kB]\n",
      "Get:42 http://deb.debian.org/debian buster/main amd64 libgl1 amd64 1.1.0-1 [91.1 kB]\n",
      "Get:43 http://deb.debian.org/debian buster/main amd64 libgif7 amd64 5.1.4-3 [43.3 kB]\n",
      "Get:44 http://deb.debian.org/debian buster/main amd64 default-jre amd64 2:1.11-71 [1044 B]\n",
      "Get:45 http://deb.debian.org/debian buster/main amd64 default-jdk-headless amd64 2:1.11-71 [1104 B]\n",
      "Get:46 http://deb.debian.org/debian buster/main amd64 default-jdk amd64 2:1.11-71 [1056 B]\n",
      "Get:47 http://security.debian.org/debian-security buster/updates/main amd64 openjdk-11-jre amd64 11.0.7+10-3~deb10u1 [34.3 kB]\n",
      "Get:48 http://security.debian.org/debian-security buster/updates/main amd64 openjdk-11-jdk-headless amd64 11.0.7+10-3~deb10u1 [215 MB]\n",
      "Get:49 http://security.debian.org/debian-security buster/updates/main amd64 openjdk-11-jdk amd64 11.0.7+10-3~deb10u1 [2607 kB]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 279 MB in 5s (53.8 MB/s)\n",
      "Selecting previously unselected package java-common.\n",
      "(Reading database ... 24603 files and directories currently installed.)\n",
      "Preparing to unpack .../00-java-common_0.71_all.deb ...\n",
      "Unpacking java-common (0.71) ...\n",
      "Selecting previously unselected package libavahi-common-data:amd64.\n",
      "Preparing to unpack .../01-libavahi-common-data_0.7-4+b1_amd64.deb ...\n",
      "Unpacking libavahi-common-data:amd64 (0.7-4+b1) ...\n",
      "Selecting previously unselected package libavahi-common3:amd64.\n",
      "Preparing to unpack .../02-libavahi-common3_0.7-4+b1_amd64.deb ...\n",
      "Unpacking libavahi-common3:amd64 (0.7-4+b1) ...\n",
      "Selecting previously unselected package libdbus-1-3:amd64.\n",
      "Preparing to unpack .../03-libdbus-1-3_1.12.16-1_amd64.deb ...\n",
      "Unpacking libdbus-1-3:amd64 (1.12.16-1) ...\n",
      "Selecting previously unselected package libavahi-client3:amd64.\n",
      "Preparing to unpack .../04-libavahi-client3_0.7-4+b1_amd64.deb ...\n",
      "Unpacking libavahi-client3:amd64 (0.7-4+b1) ...\n",
      "Selecting previously unselected package libcups2:amd64.\n",
      "Preparing to unpack .../05-libcups2_2.2.10-6+deb10u3_amd64.deb ...\n",
      "Unpacking libcups2:amd64 (2.2.10-6+deb10u3) ...\n",
      "Selecting previously unselected package libnspr4:amd64.\n",
      "Preparing to unpack .../06-libnspr4_2%3a4.20-1_amd64.deb ...\n",
      "Unpacking libnspr4:amd64 (2:4.20-1) ...\n",
      "Selecting previously unselected package libnss3:amd64.\n",
      "Preparing to unpack .../07-libnss3_2%3a3.42.1-1+deb10u2_amd64.deb ...\n",
      "Unpacking libnss3:amd64 (2:3.42.1-1+deb10u2) ...\n",
      "Selecting previously unselected package libasound2-data.\n",
      "Preparing to unpack .../08-libasound2-data_1.1.8-1_all.deb ...\n",
      "Unpacking libasound2-data (1.1.8-1) ...\n",
      "Selecting previously unselected package libasound2:amd64.\n",
      "Preparing to unpack .../09-libasound2_1.1.8-1_amd64.deb ...\n",
      "Unpacking libasound2:amd64 (1.1.8-1) ...\n",
      "Selecting previously unselected package libpcsclite1:amd64.\n",
      "Preparing to unpack .../10-libpcsclite1_1.8.24-1_amd64.deb ...\n",
      "Unpacking libpcsclite1:amd64 (1.8.24-1) ...\n",
      "Selecting previously unselected package libxi6:amd64.\n",
      "Preparing to unpack .../11-libxi6_2%3a1.7.9-1_amd64.deb ...\n",
      "Unpacking libxi6:amd64 (2:1.7.9-1) ...\n",
      "Selecting previously unselected package libxtst6:amd64.\n",
      "Preparing to unpack .../12-libxtst6_2%3a1.2.3-1_amd64.deb ...\n",
      "Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n",
      "Selecting previously unselected package openjdk-11-jre-headless:amd64.\n",
      "Preparing to unpack .../13-openjdk-11-jre-headless_11.0.7+10-3~deb10u1_amd64.deb ...\n",
      "Unpacking openjdk-11-jre-headless:amd64 (11.0.7+10-3~deb10u1) ...\n",
      "Selecting previously unselected package default-jre-headless.\n",
      "Preparing to unpack .../14-default-jre-headless_2%3a1.11-71_amd64.deb ...\n",
      "Unpacking default-jre-headless (2:1.11-71) ...\n",
      "Selecting previously unselected package ca-certificates-java.\n",
      "Preparing to unpack .../15-ca-certificates-java_20190405_all.deb ...\n",
      "Unpacking ca-certificates-java (20190405) ...\n",
      "Selecting previously unselected package libglvnd0:amd64.\n",
      "Preparing to unpack .../16-libglvnd0_1.1.0-1_amd64.deb ...\n",
      "Unpacking libglvnd0:amd64 (1.1.0-1) ...\n",
      "Selecting previously unselected package libdrm-common.\n",
      "Preparing to unpack .../17-libdrm-common_2.4.97-1_all.deb ...\n",
      "Unpacking libdrm-common (2.4.97-1) ...\n",
      "Selecting previously unselected package libdrm2:amd64.\n",
      "Preparing to unpack .../18-libdrm2_2.4.97-1_amd64.deb ...\n",
      "Unpacking libdrm2:amd64 (2.4.97-1) ...\n",
      "Selecting previously unselected package libglapi-mesa:amd64.\n",
      "Preparing to unpack .../19-libglapi-mesa_18.3.6-2+deb10u1_amd64.deb ...\n",
      "Unpacking libglapi-mesa:amd64 (18.3.6-2+deb10u1) ...\n",
      "Selecting previously unselected package libx11-xcb1:amd64.\n",
      "Preparing to unpack .../20-libx11-xcb1_2%3a1.6.7-1_amd64.deb ...\n",
      "Unpacking libx11-xcb1:amd64 (2:1.6.7-1) ...\n",
      "Selecting previously unselected package libxcb-dri2-0:amd64.\n",
      "Preparing to unpack .../21-libxcb-dri2-0_1.13.1-2_amd64.deb ...\n",
      "Unpacking libxcb-dri2-0:amd64 (1.13.1-2) ...\n",
      "Selecting previously unselected package libxcb-dri3-0:amd64.\n",
      "Preparing to unpack .../22-libxcb-dri3-0_1.13.1-2_amd64.deb ...\n",
      "Unpacking libxcb-dri3-0:amd64 (1.13.1-2) ...\n",
      "Selecting previously unselected package libxcb-glx0:amd64.\n",
      "Preparing to unpack .../23-libxcb-glx0_1.13.1-2_amd64.deb ...\n",
      "Unpacking libxcb-glx0:amd64 (1.13.1-2) ...\n",
      "Selecting previously unselected package libxcb-present0:amd64.\n",
      "Preparing to unpack .../24-libxcb-present0_1.13.1-2_amd64.deb ...\n",
      "Unpacking libxcb-present0:amd64 (1.13.1-2) ...\n",
      "Selecting previously unselected package libxcb-sync1:amd64.\n",
      "Preparing to unpack .../25-libxcb-sync1_1.13.1-2_amd64.deb ...\n",
      "Unpacking libxcb-sync1:amd64 (1.13.1-2) ...\n",
      "Selecting previously unselected package libxfixes3:amd64.\n",
      "Preparing to unpack .../26-libxfixes3_1%3a5.0.3-1_amd64.deb ...\n",
      "Unpacking libxfixes3:amd64 (1:5.0.3-1) ...\n",
      "Selecting previously unselected package libxdamage1:amd64.\n",
      "Preparing to unpack .../27-libxdamage1_1%3a1.1.4-3+b3_amd64.deb ...\n",
      "Unpacking libxdamage1:amd64 (1:1.1.4-3+b3) ...\n",
      "Selecting previously unselected package libxshmfence1:amd64.\n",
      "Preparing to unpack .../28-libxshmfence1_1.3-1_amd64.deb ...\n",
      "Unpacking libxshmfence1:amd64 (1.3-1) ...\n",
      "Selecting previously unselected package libxxf86vm1:amd64.\n",
      "Preparing to unpack .../29-libxxf86vm1_1%3a1.1.4-1+b2_amd64.deb ...\n",
      "Unpacking libxxf86vm1:amd64 (1:1.1.4-1+b2) ...\n",
      "Selecting previously unselected package libdrm-amdgpu1:amd64.\n",
      "Preparing to unpack .../30-libdrm-amdgpu1_2.4.97-1_amd64.deb ...\n",
      "Unpacking libdrm-amdgpu1:amd64 (2.4.97-1) ...\n",
      "Selecting previously unselected package libpciaccess0:amd64.\n",
      "Preparing to unpack .../31-libpciaccess0_0.14-1_amd64.deb ...\n",
      "Unpacking libpciaccess0:amd64 (0.14-1) ...\n",
      "Selecting previously unselected package libdrm-intel1:amd64.\n",
      "Preparing to unpack .../32-libdrm-intel1_2.4.97-1_amd64.deb ...\n",
      "Unpacking libdrm-intel1:amd64 (2.4.97-1) ...\n",
      "Selecting previously unselected package libdrm-nouveau2:amd64.\n",
      "Preparing to unpack .../33-libdrm-nouveau2_2.4.97-1_amd64.deb ...\n",
      "Unpacking libdrm-nouveau2:amd64 (2.4.97-1) ...\n",
      "Selecting previously unselected package libdrm-radeon1:amd64.\n",
      "Preparing to unpack .../34-libdrm-radeon1_2.4.97-1_amd64.deb ...\n",
      "Unpacking libdrm-radeon1:amd64 (2.4.97-1) ...\n",
      "Selecting previously unselected package libllvm7:amd64.\n",
      "Preparing to unpack .../35-libllvm7_1%3a7.0.1-8_amd64.deb ...\n",
      "Unpacking libllvm7:amd64 (1:7.0.1-8) ...\n",
      "Selecting previously unselected package libsensors-config.\n",
      "Preparing to unpack .../36-libsensors-config_1%3a3.5.0-3_all.deb ...\n",
      "Unpacking libsensors-config (1:3.5.0-3) ...\n",
      "Selecting previously unselected package libsensors5:amd64.\n",
      "Preparing to unpack .../37-libsensors5_1%3a3.5.0-3_amd64.deb ...\n",
      "Unpacking libsensors5:amd64 (1:3.5.0-3) ...\n",
      "Selecting previously unselected package libgl1-mesa-dri:amd64.\n",
      "Preparing to unpack .../38-libgl1-mesa-dri_18.3.6-2+deb10u1_amd64.deb ...\n",
      "Unpacking libgl1-mesa-dri:amd64 (18.3.6-2+deb10u1) ...\n",
      "Selecting previously unselected package libglx-mesa0:amd64.\n",
      "Preparing to unpack .../39-libglx-mesa0_18.3.6-2+deb10u1_amd64.deb ...\n",
      "Unpacking libglx-mesa0:amd64 (18.3.6-2+deb10u1) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package libglx0:amd64.\n",
      "Preparing to unpack .../40-libglx0_1.1.0-1_amd64.deb ...\n",
      "Unpacking libglx0:amd64 (1.1.0-1) ...\n",
      "Selecting previously unselected package libgl1:amd64.\n",
      "Preparing to unpack .../41-libgl1_1.1.0-1_amd64.deb ...\n",
      "Unpacking libgl1:amd64 (1.1.0-1) ...\n",
      "Selecting previously unselected package libgif7:amd64.\n",
      "Preparing to unpack .../42-libgif7_5.1.4-3_amd64.deb ...\n",
      "Unpacking libgif7:amd64 (5.1.4-3) ...\n",
      "Selecting previously unselected package openjdk-11-jre:amd64.\n",
      "Preparing to unpack .../43-openjdk-11-jre_11.0.7+10-3~deb10u1_amd64.deb ...\n",
      "Unpacking openjdk-11-jre:amd64 (11.0.7+10-3~deb10u1) ...\n",
      "Selecting previously unselected package default-jre.\n",
      "Preparing to unpack .../44-default-jre_2%3a1.11-71_amd64.deb ...\n",
      "Unpacking default-jre (2:1.11-71) ...\n",
      "Selecting previously unselected package openjdk-11-jdk-headless:amd64.\n",
      "Preparing to unpack .../45-openjdk-11-jdk-headless_11.0.7+10-3~deb10u1_amd64.deb ...\n",
      "Unpacking openjdk-11-jdk-headless:amd64 (11.0.7+10-3~deb10u1) ...\n",
      "Selecting previously unselected package default-jdk-headless.\n",
      "Preparing to unpack .../46-default-jdk-headless_2%3a1.11-71_amd64.deb ...\n",
      "Unpacking default-jdk-headless (2:1.11-71) ...\n",
      "Selecting previously unselected package openjdk-11-jdk:amd64.\n",
      "Preparing to unpack .../47-openjdk-11-jdk_11.0.7+10-3~deb10u1_amd64.deb ...\n",
      "Unpacking openjdk-11-jdk:amd64 (11.0.7+10-3~deb10u1) ...\n",
      "Selecting previously unselected package default-jdk.\n",
      "Preparing to unpack .../48-default-jdk_2%3a1.11-71_amd64.deb ...\n",
      "Unpacking default-jdk (2:1.11-71) ...\n",
      "Setting up libxcb-dri3-0:amd64 (1.13.1-2) ...\n",
      "Setting up libx11-xcb1:amd64 (2:1.6.7-1) ...\n",
      "Setting up libpciaccess0:amd64 (0.14-1) ...\n",
      "Setting up libxi6:amd64 (2:1.7.9-1) ...\n",
      "Setting up java-common (0.71) ...\n",
      "Setting up libglvnd0:amd64 (1.1.0-1) ...\n",
      "Setting up libxtst6:amd64 (2:1.2.3-1) ...\n",
      "Setting up libxcb-glx0:amd64 (1.13.1-2) ...\n",
      "Setting up libsensors-config (1:3.5.0-3) ...\n",
      "Setting up libxxf86vm1:amd64 (1:1.1.4-1+b2) ...\n",
      "Setting up libxcb-present0:amd64 (1.13.1-2) ...\n",
      "Setting up libasound2-data (1.1.8-1) ...\n",
      "Setting up libnspr4:amd64 (2:4.20-1) ...\n",
      "Setting up libxfixes3:amd64 (1:5.0.3-1) ...\n",
      "Setting up libxcb-sync1:amd64 (1.13.1-2) ...\n",
      "Setting up libavahi-common-data:amd64 (0.7-4+b1) ...\n",
      "Setting up libdbus-1-3:amd64 (1.12.16-1) ...\n",
      "Setting up libpcsclite1:amd64 (1.8.24-1) ...\n",
      "Setting up libsensors5:amd64 (1:3.5.0-3) ...\n",
      "Setting up libglapi-mesa:amd64 (18.3.6-2+deb10u1) ...\n",
      "Setting up libxcb-dri2-0:amd64 (1.13.1-2) ...\n",
      "Setting up libgif7:amd64 (5.1.4-3) ...\n",
      "Setting up libxshmfence1:amd64 (1.3-1) ...\n",
      "Setting up libasound2:amd64 (1.1.8-1) ...\n",
      "Setting up libllvm7:amd64 (1:7.0.1-8) ...\n",
      "Setting up libdrm-common (2.4.97-1) ...\n",
      "Setting up libxdamage1:amd64 (1:1.1.4-3+b3) ...\n",
      "Setting up libavahi-common3:amd64 (0.7-4+b1) ...\n",
      "Setting up libnss3:amd64 (2:3.42.1-1+deb10u2) ...\n",
      "Setting up libdrm2:amd64 (2.4.97-1) ...\n",
      "Setting up libavahi-client3:amd64 (0.7-4+b1) ...\n",
      "Setting up libdrm-amdgpu1:amd64 (2.4.97-1) ...\n",
      "Setting up libdrm-nouveau2:amd64 (2.4.97-1) ...\n",
      "Setting up libdrm-radeon1:amd64 (2.4.97-1) ...\n",
      "Setting up libdrm-intel1:amd64 (2.4.97-1) ...\n",
      "Setting up libgl1-mesa-dri:amd64 (18.3.6-2+deb10u1) ...\n",
      "Setting up libcups2:amd64 (2.2.10-6+deb10u3) ...\n",
      "Setting up libglx-mesa0:amd64 (18.3.6-2+deb10u1) ...\n",
      "Setting up libglx0:amd64 (1.1.0-1) ...\n",
      "Setting up libgl1:amd64 (1.1.0-1) ...\n",
      "Setting up ca-certificates-java (20190405) ...\n",
      "head: cannot open '/etc/ssl/certs/java/cacerts' for reading: No such file or directory\n",
      "Adding debian:GTS_Root_R4.pem\n",
      "Adding debian:Chambers_of_Commerce_Root_-_2008.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G2.pem\n",
      "Adding debian:QuoVadis_Root_CA_3.pem\n",
      "Adding debian:IdenTrust_Commercial_Root_CA_1.pem\n",
      "Adding debian:E-Tugra_Certification_Authority.pem\n",
      "Adding debian:Hongkong_Post_Root_CA_3.pem\n",
      "Adding debian:CA_Disig_Root_R2.pem\n",
      "Adding debian:NetLock_Arany_=Class_Gold=_Főtanúsítvány.pem\n",
      "Adding debian:QuoVadis_Root_CA.pem\n",
      "Adding debian:TUBITAK_Kamu_SM_SSL_Kok_Sertifikasi_-_Surum_1.pem\n",
      "Adding debian:XRamp_Global_CA_Root.pem\n",
      "Adding debian:SZAFIR_ROOT_CA2.pem\n",
      "Adding debian:Security_Communication_Root_CA.pem\n",
      "Adding debian:GTS_Root_R1.pem\n",
      "Adding debian:Hongkong_Post_Root_CA_1.pem\n",
      "Adding debian:AC_RAIZ_FNMT-RCM.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_EV_2009.pem\n",
      "Adding debian:Trustis_FPS_Root_CA.pem\n",
      "Adding debian:IdenTrust_Public_Sector_Root_CA_1.pem\n",
      "Adding debian:emSign_Root_CA_-_G1.pem\n",
      "Adding debian:DigiCert_Global_Root_G3.pem\n",
      "Adding debian:Certigna.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_CA.pem\n",
      "Adding debian:AffirmTrust_Commercial.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_2009.pem\n",
      "Adding debian:Global_Chambersign_Root_-_2008.pem\n",
      "Adding debian:Amazon_Root_CA_2.pem\n",
      "Adding debian:TeliaSonera_Root_CA_v1.pem\n",
      "Adding debian:TrustCor_RootCert_CA-1.pem\n",
      "Adding debian:SwissSign_Gold_CA_-_G2.pem\n",
      "Adding debian:Amazon_Root_CA_3.pem\n",
      "Adding debian:Microsec_e-Szigno_Root_CA_2009.pem\n",
      "Adding debian:EC-ACC.pem\n",
      "Adding debian:Entrust.net_Premium_2048_Secure_Server_CA.pem\n",
      "Adding debian:COMODO_RSA_Certification_Authority.pem\n",
      "Adding debian:emSign_Root_CA_-_C1.pem\n",
      "Adding debian:DigiCert_High_Assurance_EV_Root_CA.pem\n",
      "Adding debian:GDCA_TrustAUTH_R5_ROOT.pem\n",
      "Adding debian:Certigna_Root_CA.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_2.pem\n",
      "Adding debian:Go_Daddy_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:Certum_Trusted_Network_CA_2.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_G4.pem\n",
      "Adding debian:Baltimore_CyberTrust_Root.pem\n",
      "Adding debian:GTS_Root_R2.pem\n",
      "Adding debian:DigiCert_Trusted_Root_G4.pem\n",
      "Adding debian:USERTrust_ECC_Certification_Authority.pem\n",
      "Adding debian:QuoVadis_Root_CA_2_G3.pem\n",
      "Adding debian:SwissSign_Silver_CA_-_G2.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:Autoridad_de_Certificacion_Firmaprofesional_CIF_A62634068.pem\n",
      "Adding debian:UCA_Global_G2_Root.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_G2.pem\n",
      "Adding debian:DST_Root_CA_X3.pem\n",
      "Adding debian:COMODO_ECC_Certification_Authority.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R6.pem\n",
      "Adding debian:TWCA_Root_Certification_Authority.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_ECC_RootCA_2015.pem\n",
      "Adding debian:Cybertrust_Global_Root.pem\n",
      "Adding debian:AffirmTrust_Networking.pem\n",
      "Adding debian:COMODO_Certification_Authority.pem\n",
      "Adding debian:ISRG_Root_X1.pem\n",
      "Adding debian:UCA_Extended_Validation_Root.pem\n",
      "Adding debian:Staat_der_Nederlanden_EV_Root_CA.pem\n",
      "Adding debian:Network_Solutions_Certificate_Authority.pem\n",
      "Adding debian:Taiwan_GRCA.pem\n",
      "Adding debian:Amazon_Root_CA_4.pem\n",
      "Adding debian:Go_Daddy_Class_2_CA.pem\n",
      "Adding debian:AffirmTrust_Premium.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2011.pem\n",
      "Adding debian:ACCVRAIZ1.pem\n",
      "Adding debian:TrustCor_ECA-1.pem\n",
      "Adding debian:USERTrust_RSA_Certification_Authority.pem\n",
      "Adding debian:Staat_der_Nederlanden_Root_CA_-_G3.pem\n",
      "Adding debian:TWCA_Global_Root_CA.pem\n",
      "Adding debian:DigiCert_Global_Root_G2.pem\n",
      "Adding debian:Izenpe.com.pem\n",
      "Adding debian:ePKI_Root_Certification_Authority.pem\n",
      "Adding debian:Sonera_Class_2_Root_CA.pem\n",
      "Adding debian:QuoVadis_Root_CA_3_G3.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GA_CA.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_RSA.pem\n",
      "Adding debian:Security_Communication_RootCA2.pem\n",
      "Adding debian:Starfield_Class_2_CA.pem\n",
      "Adding debian:LuxTrust_Global_Root_2.pem\n",
      "Adding debian:SecureTrust_CA.pem\n",
      "Adding debian:Certum_Trusted_Network_CA.pem\n",
      "Adding debian:Amazon_Root_CA_1.pem\n",
      "Adding debian:SecureSign_RootCA11.pem\n",
      "Adding debian:TrustCor_RootCert_CA-2.pem\n",
      "Adding debian:DigiCert_Global_Root_CA.pem\n",
      "Adding debian:GTS_Root_R3.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GB_CA.pem\n",
      "Adding debian:Secure_Global_CA.pem\n",
      "Adding debian:AffirmTrust_Premium_ECC.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R3.pem\n",
      "Adding debian:emSign_ECC_Root_CA_-_G3.pem\n",
      "Adding debian:Buypass_Class_3_Root_CA.pem\n",
      "Adding debian:Comodo_AAA_Services_root.pem\n",
      "Adding debian:Verisign_Class_3_Public_Primary_Certification_Authority_-_G3.pem\n",
      "Adding debian:Starfield_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:QuoVadis_Root_CA_2.pem\n",
      "Adding debian:Buypass_Class_2_Root_CA.pem\n",
      "Adding debian:Actalis_Authentication_Root_CA.pem\n",
      "Adding debian:QuoVadis_Root_CA_1_G3.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G3.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_EC1.pem\n",
      "Adding debian:emSign_ECC_Root_CA_-_C3.pem\n",
      "Adding debian:EE_Certification_Centre_Root_CA.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GC_CA.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_3.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R5.pem\n",
      "Adding debian:Starfield_Services_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:CFCA_EV_ROOT.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2015.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority.pem\n",
      "Adding debian:GlobalSign_Root_CA.pem\n",
      "Adding debian:certSIGN_ROOT_CA.pem\n",
      "Adding debian:Atos_TrustedRoot_2011.pem\n",
      "Adding debian:Staat_der_Nederlanden_Root_CA_-_G2.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R4.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_RSA_R2.pem\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding debian:GlobalSign_Root_CA_-_R2.pem\n",
      "Adding debian:GeoTrust_Universal_CA_2.pem\n",
      "done.\n",
      "Setting up default-jre-headless (2:1.11-71) ...\n",
      "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
      "Processing triggers for libc-bin (2.28-10) ...\n",
      "Processing triggers for ca-certificates (20200601~deb10u1) ...\n",
      "Updating certificates in /etc/ssl/certs...\n",
      "0 added, 0 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d...\n",
      "\n",
      "done.\n",
      "done.\n",
      "Processing triggers for mime-support (3.62) ...\n",
      "Setting up openjdk-11-jre-headless:amd64 (11.0.7+10-3~deb10u1) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
      "Setting up openjdk-11-jre:amd64 (11.0.7+10-3~deb10u1) ...\n",
      "Setting up openjdk-11-jdk-headless:amd64 (11.0.7+10-3~deb10u1) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jaotc to provide /usr/bin/jaotc (jaotc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
      "Setting up default-jre (2:1.11-71) ...\n",
      "Setting up default-jdk-headless (2:1.11-71) ...\n",
      "Setting up openjdk-11-jdk:amd64 (11.0.7+10-3~deb10u1) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
      "Setting up default-jdk (2:1.11-71) ...\n",
      "Removing intermediate container 834a3072bcc4\n",
      " ---> 657521f8bbfb\n",
      "Step 5/14 : RUN rm -rf /var/lib/apt/lists/*\n",
      " ---> Running in c143cf01500a\n",
      "Removing intermediate container c143cf01500a\n",
      " ---> 318f45dc67ff\n",
      "Step 6/14 : RUN pip --no-cache-dir install multi-model-server sagemaker-inference sagemaker-training\n",
      " ---> Running in 11d0816660f6\n",
      "Collecting multi-model-server\n",
      "  Downloading multi_model_server-1.1.1-py2.py3-none-any.whl (4.5 MB)\n",
      "Collecting sagemaker-inference\n",
      "  Downloading sagemaker_inference-1.3.2.post0.tar.gz (17 kB)\n",
      "Collecting sagemaker-training\n",
      "  Downloading sagemaker_training-3.5.2.tar.gz (41 kB)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.7.0.tar.gz (449 kB)\n",
      "Collecting model-archiver\n",
      "  Downloading model_archiver-1.0.3-py2.py3-none-any.whl (20 kB)\n",
      "Collecting Pillow\n",
      "  Downloading Pillow-7.1.2-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.19.0-cp37-cp37m-manylinux2010_x86_64.whl (14.6 MB)\n",
      "Collecting six\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting retrying==1.3.3\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.14.8.tar.gz (96 kB)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.7/site-packages (from sagemaker-training) (20.1.1)\n",
      "Collecting gevent\n",
      "  Downloading gevent-20.6.2-cp37-cp37m-manylinux2010_x86_64.whl (5.4 MB)\n",
      "Collecting inotify_simple==1.2.1\n",
      "  Downloading inotify_simple-1.2.1.tar.gz (7.9 kB)\n",
      "Collecting werkzeug>=0.15.5\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting paramiko>=2.4.2\n",
      "  Downloading paramiko-2.7.1-py2.py3-none-any.whl (206 kB)\n",
      "Collecting protobuf>=3.1\n",
      "  Downloading protobuf-3.12.2-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting scipy>=1.2.2\n",
      "  Downloading scipy-1.5.0-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
      "Collecting enum-compat\n",
      "  Downloading enum_compat-0.0.3-py3-none-any.whl (1.3 kB)\n",
      "Collecting botocore<1.18.0,>=1.17.8\n",
      "  Downloading botocore-1.17.8-py2.py3-none-any.whl (6.3 MB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from gevent->sagemaker-training) (47.1.1)\n",
      "Collecting zope.interface\n",
      "  Downloading zope.interface-5.1.0-cp37-cp37m-manylinux2010_x86_64.whl (235 kB)\n",
      "Collecting zope.event\n",
      "  Downloading zope.event-4.4-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting greenlet>=0.4.16; platform_python_implementation == \"CPython\"\n",
      "  Downloading greenlet-0.4.16-cp37-cp37m-manylinux1_x86_64.whl (45 kB)\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-3.1.7-cp34-abi3-manylinux1_x86_64.whl (56 kB)\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB)\n",
      "Collecting cryptography>=2.5\n",
      "  Downloading cryptography-2.9.2-cp35-abi3-manylinux2010_x86_64.whl (2.7 MB)\n",
      "Collecting python-dateutil<3.0.0,>=2.1\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "Collecting urllib3<1.26,>=1.20; python_version != \"3.4\"\n",
      "  Downloading urllib3-1.25.9-py2.py3-none-any.whl (126 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cffi>=1.1\n",
      "  Downloading cffi-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (400 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Building wheels for collected packages: sagemaker-inference, sagemaker-training, psutil, future, retrying, boto3, inotify-simple\n",
      "  Building wheel for sagemaker-inference (setup.py): started\n",
      "  Building wheel for sagemaker-inference (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker-inference: filename=sagemaker_inference-1.3.2.post0-py2.py3-none-any.whl size=26353 sha256=3cf10c3d3331f5a98b124eb035f14bac04dd9185446a231a84f9ff1b2740c54a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-uihyol07/wheels/66/13/27/3cf29512c98be9d91fcacb44b9857fd50c2acd6c25ac1f4cf4\n",
      "  Building wheel for sagemaker-training (setup.py): started\n",
      "  Building wheel for sagemaker-training (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker-training: filename=sagemaker_training-3.5.2-cp37-cp37m-linux_x86_64.whl size=70872 sha256=06468db6108b016a2f35371a3d9841dc5f6f78406345757ba868a68536ad0995\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-uihyol07/wheels/c7/18/90/9d73a2ef05e92de986ee06c2b50dbab071764edefe3456e238\n",
      "  Building wheel for psutil (setup.py): started\n",
      "  Building wheel for psutil (setup.py): finished with status 'done'\n",
      "  Created wheel for psutil: filename=psutil-5.7.0-cp37-cp37m-linux_x86_64.whl size=281055 sha256=6727eb4320fd2c3d72fccfa1d8a0a4d2312b2c8a82a0c12a53d70879145447df\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-uihyol07/wheels/b6/e7/50/aee9cc966163d74430f13f208171dee22f11efa4a4a826661c\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=1c1d2a0b48bad14a0521a80c7963edbe5765214db0d9ef90a98b5dca3a65b4bc\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-uihyol07/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "  Building wheel for retrying (setup.py): started\n",
      "  Building wheel for retrying (setup.py): finished with status 'done'\n",
      "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11430 sha256=aceec06aee56f0039f7bfa31182f69c15d0ace9c377e804af4388b1366cbe43d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-uihyol07/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n",
      "  Building wheel for boto3 (setup.py): started\n",
      "  Building wheel for boto3 (setup.py): finished with status 'done'\n",
      "  Created wheel for boto3: filename=boto3-1.14.8-py2.py3-none-any.whl size=127641 sha256=8086ae67139e4cbf7b3af45a56ecf5f7bd4b2fe78a17e63909a40b67f69f7dfa\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-uihyol07/wheels/90/ec/ac/9d61dff49e7ea6ac0fba43cde75b5d5f382bd52463d204839b\n",
      "  Building wheel for inotify-simple (setup.py): started\n",
      "  Building wheel for inotify-simple (setup.py): finished with status 'done'\n",
      "  Created wheel for inotify-simple: filename=inotify_simple-1.2.1-py3-none-any.whl size=8203 sha256=eb0680fa451d5815a59f5672d7666136491f6c3d8f80722bdd31f24437f01638\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-uihyol07/wheels/ef/7e/4a/bfeb3216a60ab5e077958f5a1e980cc3de9663155cfb31c660\n",
      "Successfully built sagemaker-inference sagemaker-training psutil future retrying boto3 inotify-simple\n",
      "Installing collected packages: psutil, enum-compat, future, model-archiver, Pillow, multi-model-server, numpy, six, retrying, sagemaker-inference, jmespath, python-dateutil, docutils, urllib3, botocore, s3transfer, boto3, zope.interface, zope.event, greenlet, gevent, inotify-simple, werkzeug, pycparser, cffi, bcrypt, pynacl, cryptography, paramiko, protobuf, scipy, sagemaker-training\n",
      "Successfully installed Pillow-7.1.2 bcrypt-3.1.7 boto3-1.14.8 botocore-1.17.8 cffi-1.14.0 cryptography-2.9.2 docutils-0.15.2 enum-compat-0.0.3 future-0.18.2 gevent-20.6.2 greenlet-0.4.16 inotify-simple-1.2.1 jmespath-0.10.0 model-archiver-1.0.3 multi-model-server-1.1.1 numpy-1.19.0 paramiko-2.7.1 protobuf-3.12.2 psutil-5.7.0 pycparser-2.20 pynacl-1.4.0 python-dateutil-2.8.1 retrying-1.3.3 s3transfer-0.3.3 sagemaker-inference-1.3.2.post0 sagemaker-training-3.5.2 scipy-1.5.0 six-1.15.0 urllib3-1.25.9 werkzeug-1.0.1 zope.event-4.4 zope.interface-5.1.0\n",
      "Removing intermediate container 11d0816660f6\n",
      " ---> 8059cacbe090\n",
      "Step 7/14 : RUN pip --no-cache-dir install pandas numpy scipy scikit-learn\n",
      " ---> Running in 82f87b526137\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.0.5-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (1.19.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/site-packages (1.5.0)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.1-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-0.15.1-py3-none-any.whl (298 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Installing collected packages: pytz, pandas, joblib, threadpoolctl, scikit-learn\n",
      "Successfully installed joblib-0.15.1 pandas-1.0.5 pytz-2020.1 scikit-learn-0.23.1 threadpoolctl-2.1.0\n",
      "Removing intermediate container 82f87b526137\n",
      " ---> 705a76ac9dc5\n",
      "Step 8/14 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Running in f3cfe97914ec\n",
      "Removing intermediate container f3cfe97914ec\n",
      " ---> 91b190d9ff13\n",
      "Step 9/14 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Running in 286ff2189d8f\n",
      "Removing intermediate container 286ff2189d8f\n",
      " ---> b09a11dd658c\n",
      "Step 10/14 : ENV PYTHONPATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Running in 4d2b726038c8\n",
      "Removing intermediate container 4d2b726038c8\n",
      " ---> 3604646bb85f\n",
      "Step 11/14 : COPY main.py /opt/ml/code/main.py\n",
      " ---> cec26c83ad1b\n",
      "Step 12/14 : COPY train.py /opt/ml/code/train.py\n",
      " ---> 5cec12776212\n",
      "Step 13/14 : COPY handler.py /opt/ml/code/serving/handler.py\n",
      " ---> 0752869a4a66\n",
      "Step 14/14 : ENTRYPOINT [\"python\", \"/opt/ml/code/main.py\"]\n",
      " ---> Running in 80721fa46e46\n",
      "Removing intermediate container 80721fa46e46\n",
      " ---> 958076859b85\n",
      "Successfully built 958076859b85\n",
      "Successfully tagged iris_model:1.0\n"
     ]
    }
   ],
   "source": [
    "!docker build -f Dockerfile -t iris_model:1.0 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Now that we have the algorithm image we can run it to train/deploy a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then, we need to prepare the dataset\n",
    "You'll see that we're splitting the dataset into training and validation and also saving these two subsets of the dataset into csv files. These files will be then uploaded to an S3 Bucket and shared with SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iris_id</th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iris_id  sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "0      0.0                5.1               3.5                1.4   \n",
       "1      0.0                4.9               3.0                1.4   \n",
       "2      0.0                4.7               3.2                1.3   \n",
       "3      0.0                4.6               3.1                1.5   \n",
       "4      0.0                5.0               3.6                1.4   \n",
       "\n",
       "   petal width (cm)  \n",
       "0               0.2  \n",
       "1               0.2  \n",
       "2               0.2  \n",
       "3               0.2  \n",
       "4               0.2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!rm -rf input\n",
    "!mkdir -p input/data/training\n",
    "!mkdir -p input/data/testing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "dataset = np.insert(iris.data, 0, iris.target,axis=1)\n",
    "\n",
    "df = pd.DataFrame(data=dataset, columns=[\"iris_id\"] + iris.feature_names)\n",
    "X = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "train_df = X_train.copy()\n",
    "train_df.insert(0, \"iris_id\", y_train)\n",
    "train_df.to_csv(\"input/data/training/training.csv\", sep=\",\", header=None, index=None)\n",
    "\n",
    "test_df = X_test.copy()\n",
    "test_df.insert(0, \"iris_id\", y_test)\n",
    "test_df.to_csv(\"input/data/testing/testing.csv\", sep=\",\", header=None, index=None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Just a basic local test, using the local Docker daemon\n",
    "Here we will simulate SageMaker calling our docker container for training and serving. We'll do that using the built-in Docker Daemon of the Jupyter Notebook Instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf input/config && mkdir -p input/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/config/hyperparameters.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/config/hyperparameters.json\n",
    "{\"max_depth\": 20, \"n_jobs\": 4, \"n_estimators\": 120}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/config/resourceconfig.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/config/resourceconfig.json\n",
    "{\"current_host\": \"localhost\", \"hosts\": [\"algo-1-kipw9\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/config/inputdataconfig.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/config/inputdataconfig.json\n",
    "{\"training\": {\"TrainingInputMode\": \"File\"}, \"testing\": {\"TrainingInputMode\": \"File\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "done\n",
      "Training mode\n",
      "Training the classifier\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 120 out of 120 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 120 out of 120 | elapsed:    0.0s finished\n",
      "Score: 0.98\n",
      "done\n",
      "CPU times: user 47.5 ms, sys: 20.3 ms, total: 67.8 ms\n",
      "Wall time: 2.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!rm -rf model/\n",
    "!mkdir -p model\n",
    "\n",
    "print( \"Training...\")\n",
    "!docker run --rm --name \"my_model\" \\\n",
    "    -v \"$PWD/model:/opt/ml/model\" \\\n",
    "    -v \"$PWD/input:/opt/ml/input\" iris_model:1.0 train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 This is the serving test. It simulates an Endpoint exposed by Sagemaker\n",
    "\n",
    "After you execute the next cell, this Jupyter notebook will freeze. A webservice will be exposed at the port 8080. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Warning: Calling MMS with mxnet-model-server. Please move to multi-model-server.\n",
      "2020-06-23 19:35:25,590 [INFO ] main com.amazonaws.ml.mms.ModelServer - \n",
      "MMS Home: /usr/local/lib/python3.7/site-packages\n",
      "Current directory: /\n",
      "Temp directory: /tmp\n",
      "Number of GPUs: 0\n",
      "Number of CPUs: 4\n",
      "Max heap size: 4012 M\n",
      "Python executable: /usr/local/bin/python\n",
      "Config file: /etc/sagemaker-mms.properties\n",
      "Inference address: http://0.0.0.0:8080\n",
      "Management address: http://0.0.0.0:8080\n",
      "Model Store: /.sagemaker/mms/models\n",
      "Initial Models: ALL\n",
      "Log dir: /logs\n",
      "Metrics dir: /logs\n",
      "Netty threads: 0\n",
      "Netty client threads: 0\n",
      "Default workers per model: 4\n",
      "Blacklist Regex: N/A\n",
      "Maximum Response Size: 6553500\n",
      "Maximum Request Size: 6553500\n",
      "Preload model: false\n",
      "Prefer direct buffer: false\n",
      "2020-06-23 19:35:25,674 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-9000-model\n",
      "2020-06-23 19:35:25,763 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - model_service_worker started with args: --sock-type unix --sock-name /tmp/.mms.sock.9000 --handler serving.handler --model-path /.sagemaker/mms/models/model --model-name model --preload-model false --tmp-dir /tmp\n",
      "2020-06-23 19:35:25,765 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /tmp/.mms.sock.9000\n",
      "2020-06-23 19:35:25,765 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID] 33\n",
      "2020-06-23 19:35:25,766 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "2020-06-23 19:35:25,766 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.7.7\n",
      "2020-06-23 19:35:25,767 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\n",
      "2020-06-23 19:35:25,785 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\n",
      "2020-06-23 19:35:25,792 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /tmp/.mms.sock.9000\n",
      "2020-06-23 19:35:25,793 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /tmp/.mms.sock.9000\n",
      "2020-06-23 19:35:25,792 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /tmp/.mms.sock.9000\n",
      "2020-06-23 19:35:25,792 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /tmp/.mms.sock.9000\n",
      "2020-06-23 19:35:25,879 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\n",
      "Model server started.\n",
      "2020-06-23 19:35:25,883 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /tmp/.mms.sock.9000.\n",
      "2020-06-23 19:35:25,889 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /tmp/.mms.sock.9000.\n",
      "2020-06-23 19:35:25,891 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /tmp/.mms.sock.9000.\n",
      "2020-06-23 19:35:25,893 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /tmp/.mms.sock.9000.\n",
      "2020-06-23 19:35:25,903 [WARN ] pool-2-thread-1 com.amazonaws.ml.mms.metrics.MetricCollector - worker pid is not available yet.\n",
      "2020-06-23 19:35:26,850 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242acfffe110002-0000000e-00000004-1e75cc89b9bd937e-b8c573a9\n",
      "2020-06-23 19:35:26,852 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242acfffe110002-0000000e-00000001-fcd84c89b9bd937e-32d83160\n",
      "2020-06-23 19:35:26,854 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242acfffe110002-0000000e-00000003-8da9cc89b9bd937e-72b3bb8b\n",
      "2020-06-23 19:35:26,856 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 851\n",
      "2020-06-23 19:35:26,856 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 855\n",
      "2020-06-23 19:35:26,857 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 868\n",
      "2020-06-23 19:35:26,858 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-3\n",
      "2020-06-23 19:35:26,859 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-1\n",
      "2020-06-23 19:35:26,858 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-4\n",
      "2020-06-23 19:35:26,860 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242acfffe110002-0000000e-00000000-74478c89b9bd937e-1cebc853\n",
      "2020-06-23 19:35:26,860 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 882\n",
      "2020-06-23 19:35:26,862 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-2\n"
     ]
    }
   ],
   "source": [
    "!docker run --rm --name \"my_model\" \\\n",
    "    -p 8080:8080 \\\n",
    "    -v \"$PWD/model:/opt/ml/model\" \\\n",
    "    -v \"$PWD/input:/opt/ml/input\" iris_model:1.0 serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> While the above cell is running, click here [TEST NOTEBOOK](02_Testing%20our%20local%20model%20server.ipynb) to run some tests.\n",
    "\n",
    "> After you finish the tests, press **STOP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3 - Integrated Test: Everything seems ok, now it's time to put all together\n",
    "\n",
    "We'll start by running a local **CodeBuild** test, to check the buildspec and also deploy this image into the container registry. Remember that SageMaker will only see images published to ECR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sts_client = boto3.client(\"sts\")\n",
    "session = boto3.session.Session()\n",
    "\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = session.region_name\n",
    "credentials = session.get_credentials()\n",
    "credentials = credentials.get_frozen_credentials()\n",
    "\n",
    "repo_name=\"iris-model\"\n",
    "image_tag=\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo rm -rf tests && mkdir -p tests\n",
    "!cp handler.py main.py train.py Dockerfile buildspec.yml tests/\n",
    "with open(\"tests/vars.env\", \"w\") as f:\n",
    "    f.write(\"AWS_ACCOUNT_ID=%s\\n\" % account_id)\n",
    "    f.write(\"IMAGE_TAG=%s\\n\" % image_tag)\n",
    "    f.write(\"IMAGE_REPO_NAME=%s\\n\" % repo_name)\n",
    "    f.write(\"AWS_DEFAULT_REGION=%s\\n\" % region)\n",
    "    f.write(\"AWS_ACCESS_KEY_ID=%s\\n\" % credentials.access_key)\n",
    "    f.write(\"AWS_SECRET_ACCESS_KEY=%s\\n\" % credentials.secret_key)\n",
    "    f.write(\"AWS_SESSION_TOKEN=%s\\n\" % credentials.token )\n",
    "    f.close()\n",
    "\n",
    "!cat tests/vars.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "!/tmp/aws-codebuild/local_builds/codebuild_build.sh \\\n",
    "    -a \"$PWD/tests/output\" \\\n",
    "    -s \"$PWD/tests\" \\\n",
    "    -i \"samirsouza/aws-codebuild-standard:3.0\" \\\n",
    "    -e \"$PWD/tests/vars.env\" \\\n",
    "    -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now that we have an image deployed in the ECR repo we can also run some local tests using the SageMaker Estimator.\n",
    "\n",
    "> Click on this [TEST NOTEBOOK](03_Testing%20the%20container%20using%20SageMaker%20Estimator.ipynb) to run some tests.\n",
    "\n",
    "> After you finishing the tests, come back to **this notebook** to push the assets to the Git Repo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 4 - Let's push all the assets to the Git Repo connected to the Build pipeline\n",
    "There is a CodePipeine configured to keep listeining to this Git Repo and start a new Building process with CodeBuild."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ../../../mlops\n",
    "git checkout iris_model\n",
    "cp $OLDPWD/buildspec.yml $OLDPWD/handler.py $OLDPWD/train.py $OLDPWD/main.py $OLDPWD/Dockerfile .\n",
    "\n",
    "git add --all\n",
    "git commit -a -m \" - files for building an iris model image\"\n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Alright, now open the AWS console and go to the **CodePipeline** dashboard. Look for a pipeline called **mlops-iris-model**. This pipeline will deploy the final image to an ECR repo. When this process finishes, open the **Elastic Compute Registry** dashboard, in the AWS console, and check if you have an image called **iris-model:latest**. If yes, you can go to the next exercise. If not, wait a little more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
